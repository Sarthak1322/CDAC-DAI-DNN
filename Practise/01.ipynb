{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e10b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Create a simple ANN (classification) model for the Titanic Dataset using TenserFlow or pyTorch\\n\\nTasks:\\nData Preparation\\n1. Load the Titanic dataset: Load the train and test data\\n2: Preprocess the data: Normalize the input features, split the dataset into training and testing sets\\n\\nModel Architecture\\n1. Design a feedforward neural network architecture\\n2. Define the number of layers, neurons in each layer and activation function\\n\\nModel Trianing\\n1. Initialize the model parameters(weights and biases)\\n2. Define a loss function appropriate for the task\\n3. Train the model using gradient descent or any suitable optimization algorithm\\n4. Monitor the training process by observing the loss and accuracy metrics\\n\\nModel Evaluation\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Create a simple ANN (classification) model for the Titanic Dataset using TenserFlow or pyTorch\n",
    "\n",
    "Tasks:\n",
    "Data Preparation\n",
    "1. Load the Titanic dataset: Load the train and test data\n",
    "2: Preprocess the data: Normalize the input features, split the dataset into training and testing sets\n",
    "\n",
    "Model Architecture\n",
    "1. Design a feedforward neural network architecture\n",
    "2. Define the number of layers, neurons in each layer and activation function\n",
    "\n",
    "Model Trianing\n",
    "1. Initialize the model parameters(weights and biases)\n",
    "2. Define a loss function appropriate for the task\n",
    "3. Train the model using gradient descent or any suitable optimization algorithm\n",
    "4. Monitor the training process by observing the loss and accuracy metrics\n",
    "\n",
    "Model Evaluation\n",
    "1. Evaluate the trained model on the testing dataset\n",
    "2. Calculate and report the accuracy\n",
    "\n",
    "Experimentation \n",
    "1. Experiment with different hyperparameters such as learning rate , number of hidden layer and number of neurons in each layer\n",
    "2. explore different activation functions (e.g., ReLU, sigmoid, tanh) and observe their impact on the model's performance\n",
    "\n",
    "Deliverables\n",
    "1. Python code(ipynb) implementing the neural network\n",
    "2. Training loss curve plot\n",
    "3. Evaluation results saved in predictions.csv file\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f12967b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1982832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b6a8585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88feddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Survived', 'Name', 'Sex','Ticket','Cabin','Embarked'], axis=1)\n",
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df553f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a660669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthakredasani/.local/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu',kernel_initializer='he_normal', bias_initializer='zeros', input_dim = 6))\n",
    "model.add(Dense(64, activation='relu',kernel_initializer='he_normal', bias_initializer='zeros'))\n",
    "model.add(Dense(32, activation='relu',kernel_initializer='he_normal', bias_initializer='zeros'))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac88f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c862e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.6177 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6157 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6252 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5959 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5831 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6258 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5840 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6025 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6150 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6175 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6289 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6126 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6454 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6262 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5856 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5952 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6164 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6220 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6253 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6222 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6146 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6318 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5803 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 24/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6415 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 25/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6056 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 26/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6078 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 27/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6306 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 28/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5973 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 29/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6116 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 30/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6059 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 31/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6351 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 32/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6228 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 33/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6407 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 34/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6040 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 35/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6115 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 36/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5841 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 37/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6105 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 38/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6177 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 39/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6035 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 40/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6075 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 41/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5891 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 42/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6311 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 43/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6191 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 44/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6266 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 45/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6117 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 46/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6240 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 47/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5944 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 48/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5890 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 49/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6001 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 50/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6316 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f1d94ebb650>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e96bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthakredasani/.local/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 47ms/step - accuracy: 0.5354 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 2/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5770 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 3/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6253 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 4/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5773 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 5/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5996 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 6/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6438 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 7/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6478 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 8/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6043 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 9/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6248 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 10/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6090 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 11/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6210 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 12/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6392 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 13/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5970 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 14/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6048 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 15/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6161 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 16/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6061 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 17/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5944 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 18/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6276 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 19/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6085 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 20/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6052 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 21/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6089 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 22/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5999 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 23/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6454 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 24/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6388 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 25/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6200 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 26/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5788 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 27/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6052 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 28/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6046 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 29/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6218 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 30/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5991 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 31/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6035 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 32/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6153 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 33/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6306 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 34/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6299 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 35/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6386 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 36/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6550 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 37/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6091 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 38/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6203 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 39/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6093 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 40/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5940 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 41/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6042 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 42/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6264 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 43/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5849 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 44/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6347 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 45/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6136 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 46/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6103 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 47/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6155 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 48/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6578 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 49/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6175 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n",
      "Epoch 50/50\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.5917 - loss: nan - val_accuracy: 0.6157 - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f1d94d42010>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Import necessary libraries\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Dropout\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Load the Titanic dataset\n",
    "# df = pd.read_csv('Titanic.csv')\n",
    "\n",
    "# # Encode categorical features\n",
    "# df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "# df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# # Select features & target variable\n",
    "# X = df.drop(['Survived', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "# y = df['Survived']\n",
    "\n",
    "# # Normalize the input features\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "# # Split dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# # Build the feedforward neural network model\n",
    "# model = Sequential([\n",
    "#     Dense(128, activation='relu', kernel_initializer='he_normal', bias_initializer='zeros', input_shape=(X_train.shape[1],)),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(64, activation='relu', kernel_initializer='he_normal', bias_initializer='zeros'),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(32, activation='relu', kernel_initializer='he_normal', bias_initializer='zeros'),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# # Initialize model parameters (weights & biases)\n",
    "# model.build(input_shape=(None, X_train.shape[1]))  # Explicit weight initialization\n",
    "\n",
    "# # Define loss function & optimizer\n",
    "# loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "# optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "# # Train the model using gradient descent & monitor training\n",
    "# history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), batch_size=32)\n",
    "\n",
    "# # Plot Training Loss & Accuracy\n",
    "# plt.figure(figsize=(12,5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.plot(history.history['loss'], label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.title('Training vs Validation Loss')\n",
    "\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.title('Training vs Validation Accuracy')\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # Evaluate the model on the test dataset\n",
    "# test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "# print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# # Save predictions to CSV file\n",
    "# predictions = model.predict(X_test)\n",
    "# df_predictions = pd.DataFrame({'Actual': y_test, 'Predicted': (predictions.flatten() > 0.5).astype(int)})\n",
    "# df_predictions.to_csv('predictions.csv', index=False)\n",
    "# print(\"Predictions saved to 'predictions.csv'\")\n",
    "\n",
    "# # Experiment with different activation functions & hyperparameters\n",
    "# # Change activation functions: ReLU, Sigmoid, Tanh\n",
    "# # Modify number of neurons, learning rate, dropout rates for improvement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1785a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam = Adam(learning_rate = 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5b3cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:08:01.308227: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-02 11:08:01.636622: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-02 11:08:01.812996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-02 11:08:02.127443: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-02 11:08:02.210397: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-02 11:08:02.594648: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-02 11:08:08.788945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthakredasani/.local/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,573,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,707,274</span> (6.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,707,274\u001b[0m (6.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,707,274</span> (6.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,707,274\u001b[0m (6.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:09:48.187921: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2716 - loss: 2.0270"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:11:28.160223: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 122880000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 60ms/step - accuracy: 0.2717 - loss: 2.0269 - val_accuracy: 0.3883 - val_loss: 1.6923\n",
      "Epoch 2/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 57ms/step - accuracy: 0.3934 - loss: 1.6955 - val_accuracy: 0.4140 - val_loss: 1.6350\n",
      "Epoch 3/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 49ms/step - accuracy: 0.4214 - loss: 1.6094 - val_accuracy: 0.4237 - val_loss: 1.6110\n",
      "Epoch 4/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 58ms/step - accuracy: 0.4443 - loss: 1.5434 - val_accuracy: 0.4416 - val_loss: 1.5567\n",
      "Epoch 5/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 57ms/step - accuracy: 0.4625 - loss: 1.4995 - val_accuracy: 0.4519 - val_loss: 1.5365\n",
      "Epoch 6/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 46ms/step - accuracy: 0.4711 - loss: 1.4758 - val_accuracy: 0.4734 - val_loss: 1.4905\n",
      "Epoch 7/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 40ms/step - accuracy: 0.4839 - loss: 1.4454 - val_accuracy: 0.4764 - val_loss: 1.4731\n",
      "Epoch 8/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 39ms/step - accuracy: 0.4917 - loss: 1.4229 - val_accuracy: 0.4806 - val_loss: 1.4607\n",
      "Epoch 9/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 44ms/step - accuracy: 0.5002 - loss: 1.3859 - val_accuracy: 0.4837 - val_loss: 1.4508\n",
      "Epoch 10/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 46ms/step - accuracy: 0.5043 - loss: 1.3819 - val_accuracy: 0.4745 - val_loss: 1.4812\n",
      "Epoch 11/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 60ms/step - accuracy: 0.5139 - loss: 1.3481 - val_accuracy: 0.4660 - val_loss: 1.4993\n",
      "Epoch 12/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 42ms/step - accuracy: 0.5198 - loss: 1.3349 - val_accuracy: 0.4881 - val_loss: 1.4422\n",
      "Epoch 13/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 48ms/step - accuracy: 0.5208 - loss: 1.3255 - val_accuracy: 0.4696 - val_loss: 1.4754\n",
      "Epoch 14/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 59ms/step - accuracy: 0.5284 - loss: 1.3118 - val_accuracy: 0.4835 - val_loss: 1.4476\n",
      "Epoch 15/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 58ms/step - accuracy: 0.5316 - loss: 1.3065 - val_accuracy: 0.4903 - val_loss: 1.4557\n",
      "    Epoch  Training Accuracy  Validation Accuracy\n",
      "0       1            0.32462               0.3883\n",
      "1       2            0.40322               0.4140\n",
      "2       3            0.43090               0.4237\n",
      "3       4            0.44914               0.4416\n",
      "4       5            0.46244               0.4519\n",
      "5       6            0.47292               0.4734\n",
      "6       7            0.48208               0.4764\n",
      "7       8            0.49154               0.4806\n",
      "8       9            0.50178               0.4837\n",
      "9      10            0.50570               0.4745\n",
      "10     11            0.50982               0.4660\n",
      "11     12            0.51724               0.4881\n",
      "12     13            0.51874               0.4696\n",
      "13     14            0.52378               0.4835\n",
      "14     15            0.52944               0.4903\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Neueal Network for CIFAR-10 Classification Design and train a feedforward neural network with atleast 2 hidden layes to classify images from the CIFAR-10 dataset.(Dataset Link: https://www.kaggle.com/c/cifar-10/data or use code from tensorflow.keras.datasets import cifar10) Ue ReLU activation for hidden layers and softmax for output. Train for 15 epochs and report training and validation accuracy. Expected Output:\n",
    " 1.Code defining and training the network \n",
    " 2.Model Summary \n",
    " 3.Table showing accuracy for each epoch.\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(32, 32, 3)),  # Flatten image data\n",
    "    layers.Dense(512, activation='relu'),  # First hidden layer\n",
    "    layers.Dense(256, activation='relu'),  # Second hidden layer\n",
    "    layers.Dense(10, activation='softmax')  # Output layer for classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe with epoch-wise accuracy\n",
    "epoch_data = {\n",
    "    \"Epoch\": list(range(1, 16)),\n",
    "    \"Training Accuracy\": history.history['accuracy'],\n",
    "    \"Validation Accuracy\": history.history['val_accuracy']\n",
    "}\n",
    "\n",
    "accuracy_df = pd.DataFrame(epoch_data)\n",
    "print(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Q1:Neueal Network for CIFAR-10 Classification\n",
    "Design and train a feedforward neural network with atleast 2 hidden layes to classify images from the CIFAR-10 dataset.(Dataset Link: https://www.kaggle.com/c/cifar-10/data or use code from tensorflow.keras.datasets import cifar10) \n",
    "Ue ReLU activation for hidden layers and softmax for output.\n",
    "Train for 15 epochs and report training and validation accuracy.\n",
    "Expected Output:\n",
    "1.Code defining and training the network\n",
    "2.Model Summary\n",
    "3.Table showing accuracy for each epoch.\n",
    "\n",
    "Q2)Regularization in Neural Networks\n",
    "1.Add dropout layers(with dropout rate 0.3) and L2 weight regularization to the model from Q1.\n",
    "2.Train for 15 epochs and compare results with the previous moel.\n",
    "3.Explain how regularization affected overfitting.\n",
    "Expected Output:\n",
    "1.code implementing dropout and L2 regularization\n",
    "Accuracy tables before and after regularization\n",
    "3.Brief explanation on regularization impact.\n",
    "\n",
    "Q3. Optimizer Comparision\n",
    "1.Train the model from Q2 using two optimizers : SGD and Adam(use default parameters).\n",
    "2.Compare training speed and final accuracy for both optimizers.\n",
    "3.Plot loss curves and accuracy for both.\n",
    "Expected Output: \n",
    "1.Code for optimizer implementation\n",
    "2.Accuracy and loss plots for SGD and Adam\n",
    "3.Short analysis comparing optimizers.\n",
    "\n",
    "Q4: Hyperparameter Tuning\n",
    "1.Perform tuning of learning rate and batch size for the model in Q2.\n",
    "2.Use manual search (try atleast 3 learning rates and 2 batch sizes)\n",
    "3.Report the best hyper parameter combination with reasoning.\n",
    "Expected Output:\n",
    "1.Code for tuning experiments\n",
    "2.Table of showing different learning rates and batch sizes with corresponding accuracy\n",
    "3.Explanation of best choice.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dae1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize pixel values\n",
    "\n",
    "# Define CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))\n",
    "\n",
    "# Accuracy table\n",
    "import pandas as pd\n",
    "accuracy_df = pd.DataFrame({\n",
    "    \"Epoch\": list(range(1, 16)),\n",
    "    \"Training Accuracy\": history.history['accuracy'],\n",
    "    \"Validation Accuracy\": history.history['val_accuracy']\n",
    "})\n",
    "print(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908326b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define CNN with regularization\n",
    "model_reg = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(0.001)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model_reg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_reg = model_reg.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))\n",
    "\n",
    "# Compare accuracy before and after regularization\n",
    "accuracy_df[\"Training Accuracy (Reg)\"] = history_reg.history['accuracy']\n",
    "accuracy_df[\"Validation Accuracy (Reg)\"] = history_reg.history['val_accuracy']\n",
    "print(accuracy_df)\n",
    "\n",
    "# Explanation: Regularization helps prevent overfitting by reducing reliance on specific neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile models with different optimizers\n",
    "model_sgd = models.clone_model(model_reg)\n",
    "model_adam = models.clone_model(model_reg)\n",
    "\n",
    "model_sgd.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_adam.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train models\n",
    "history_sgd = model_sgd.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))\n",
    "history_adam = model_adam.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))\n",
    "\n",
    "# Plot accuracy comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_sgd.history['accuracy'], label='SGD - Train')\n",
    "plt.plot(history_sgd.history['val_accuracy'], label='SGD - Val')\n",
    "plt.plot(history_adam.history['accuracy'], label='Adam - Train')\n",
    "plt.plot(history_adam.history['val_accuracy'], label='Adam - Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Analysis: Adam converges faster, while SGD sometimes generalizes better over more epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4431d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64]\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        model_tune = models.clone_model(model_reg)\n",
    "        model_tune.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \n",
    "                           loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        history_tune = model_tune.fit(x_train, y_train, epochs=15, batch_size=bs, validation_data=(x_test, y_test))\n",
    "        \n",
    "        results.append({\"Learning Rate\": lr, \"Batch Size\": bs, \"Final Accuracy\": history_tune.history['val_accuracy'][-1]})\n",
    "\n",
    "# Display results\n",
    "tuning_df = pd.DataFrame(results)\n",
    "print(tuning_df)\n",
    "\n",
    "# Explanation: Smaller learning rates ensure stable training, while batch size impacts speed and convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd9b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e1fa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthakredasani/.local/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,573,376</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,573,376\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m2,570\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,707,274</span> (6.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,707,274\u001b[0m (6.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,707,274</span> (6.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,707,274\u001b[0m (6.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:31:19.716052: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2829 - loss: 2.0124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 11:32:54.230912: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 122880000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 55ms/step - accuracy: 0.2829 - loss: 2.0123 - val_accuracy: 0.3925 - val_loss: 1.6977\n",
      "Epoch 2/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 50ms/step - accuracy: 0.3970 - loss: 1.6850 - val_accuracy: 0.4324 - val_loss: 1.6017\n",
      "Epoch 3/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.4313 - loss: 1.5896 - val_accuracy: 0.4507 - val_loss: 1.5356\n",
      "Epoch 4/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.4504 - loss: 1.5375 - val_accuracy: 0.4279 - val_loss: 1.6026\n",
      "Epoch 5/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 49ms/step - accuracy: 0.4583 - loss: 1.5079 - val_accuracy: 0.4579 - val_loss: 1.5190\n",
      "Epoch 6/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 50ms/step - accuracy: 0.4768 - loss: 1.4669 - val_accuracy: 0.4740 - val_loss: 1.4790\n",
      "Epoch 7/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 51ms/step - accuracy: 0.4901 - loss: 1.4414 - val_accuracy: 0.4739 - val_loss: 1.4654\n",
      "Epoch 8/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 49ms/step - accuracy: 0.4927 - loss: 1.4273 - val_accuracy: 0.4530 - val_loss: 1.5391\n",
      "Epoch 9/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 44ms/step - accuracy: 0.4978 - loss: 1.3946 - val_accuracy: 0.4645 - val_loss: 1.4912\n",
      "Epoch 10/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 48ms/step - accuracy: 0.5068 - loss: 1.3813 - val_accuracy: 0.4660 - val_loss: 1.5375\n",
      "Epoch 11/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 54ms/step - accuracy: 0.5175 - loss: 1.3567 - val_accuracy: 0.4863 - val_loss: 1.4526\n",
      "Epoch 12/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.5191 - loss: 1.3381 - val_accuracy: 0.4794 - val_loss: 1.4766\n",
      "Epoch 13/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 54ms/step - accuracy: 0.5274 - loss: 1.3273 - val_accuracy: 0.4645 - val_loss: 1.5203\n",
      "Epoch 14/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.5278 - loss: 1.3169 - val_accuracy: 0.4946 - val_loss: 1.4577\n",
      "Epoch 15/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 53ms/step - accuracy: 0.5338 - loss: 1.3060 - val_accuracy: 0.4826 - val_loss: 1.4565\n",
      "    Epoch  Training Accuracy  Validation Accuracy\n",
      "0       1            0.32782               0.3925\n",
      "1       2            0.40262               0.4324\n",
      "2       3            0.43302               0.4507\n",
      "3       4            0.45116               0.4279\n",
      "4       5            0.46506               0.4579\n",
      "5       6            0.47400               0.4740\n",
      "6       7            0.48642               0.4739\n",
      "7       8            0.49310               0.4530\n",
      "8       9            0.50002               0.4645\n",
      "9      10            0.50684               0.4660\n",
      "10     11            0.51298               0.4863\n",
      "11     12            0.51736               0.4794\n",
      "12     13            0.52430               0.4645\n",
      "13     14            0.52618               0.4946\n",
      "14     15            0.53034               0.4826\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Define model\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))\n",
    "\n",
    "# Display accuracy table\n",
    "import pandas as pd\n",
    "epoch_data = {\n",
    "    \"Epoch\": list(range(1, 16)),\n",
    "    \"Training Accuracy\": history.history['accuracy'],\n",
    "    \"Validation Accuracy\": history.history['val_accuracy']\n",
    "}\n",
    "accuracy_df = pd.DataFrame(epoch_data)\n",
    "print(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acee3bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarthakredasani/.local/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-06-02 11:51:47.569440: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 614400000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 77ms/step - accuracy: 0.2103 - loss: 2.6251 - val_accuracy: 0.3181 - val_loss: 1.9692\n",
      "Epoch 2/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 67ms/step - accuracy: 0.2670 - loss: 2.0139 - val_accuracy: 0.3145 - val_loss: 1.9274\n",
      "Epoch 3/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 67ms/step - accuracy: 0.2900 - loss: 1.9621 - val_accuracy: 0.3136 - val_loss: 1.9480\n",
      "Epoch 4/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 68ms/step - accuracy: 0.2861 - loss: 1.9763 - val_accuracy: 0.3500 - val_loss: 1.8858\n",
      "Epoch 5/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 68ms/step - accuracy: 0.2940 - loss: 1.9601 - val_accuracy: 0.3413 - val_loss: 1.8901\n",
      "Epoch 6/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 69ms/step - accuracy: 0.2940 - loss: 1.9571 - val_accuracy: 0.3397 - val_loss: 1.8935\n",
      "Epoch 7/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 67ms/step - accuracy: 0.3027 - loss: 1.9457 - val_accuracy: 0.3333 - val_loss: 1.8922\n",
      "Epoch 8/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 64ms/step - accuracy: 0.3033 - loss: 1.9452 - val_accuracy: 0.3557 - val_loss: 1.8510\n",
      "Epoch 9/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 68ms/step - accuracy: 0.3019 - loss: 1.9468 - val_accuracy: 0.3300 - val_loss: 1.9239\n",
      "Epoch 10/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 68ms/step - accuracy: 0.3008 - loss: 1.9496 - val_accuracy: 0.3408 - val_loss: 1.8683\n",
      "Epoch 11/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 69ms/step - accuracy: 0.2997 - loss: 1.9460 - val_accuracy: 0.3478 - val_loss: 1.8599\n",
      "Epoch 12/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 70ms/step - accuracy: 0.2994 - loss: 1.9514 - val_accuracy: 0.3117 - val_loss: 1.9117\n",
      "Epoch 13/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 75ms/step - accuracy: 0.3053 - loss: 1.9430 - val_accuracy: 0.3476 - val_loss: 1.9213\n",
      "Epoch 14/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 79ms/step - accuracy: 0.2945 - loss: 1.9612 - val_accuracy: 0.3311 - val_loss: 1.8944\n",
      "Epoch 15/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 80ms/step - accuracy: 0.2999 - loss: 1.9459 - val_accuracy: 0.3065 - val_loss: 1.9225\n",
      "    Epoch  Training Accuracy  Validation Accuracy  Training Accuracy (Reg)  \\\n",
      "0       1            0.32782               0.3925                  0.23930   \n",
      "1       2            0.40262               0.4324                  0.27386   \n",
      "2       3            0.43302               0.4507                  0.28846   \n",
      "3       4            0.45116               0.4279                  0.29054   \n",
      "4       5            0.46506               0.4579                  0.29470   \n",
      "5       6            0.47400               0.4740                  0.29608   \n",
      "6       7            0.48642               0.4739                  0.29902   \n",
      "7       8            0.49310               0.4530                  0.30052   \n",
      "8       9            0.50002               0.4645                  0.29676   \n",
      "9      10            0.50684               0.4660                  0.30272   \n",
      "10     11            0.51298               0.4863                  0.30124   \n",
      "11     12            0.51736               0.4794                  0.30356   \n",
      "12     13            0.52430               0.4645                  0.29800   \n",
      "13     14            0.52618               0.4946                  0.29908   \n",
      "14     15            0.53034               0.4826                  0.29856   \n",
      "\n",
      "    Validation Accuracy (Reg)  \n",
      "0                      0.3181  \n",
      "1                      0.3145  \n",
      "2                      0.3136  \n",
      "3                      0.3500  \n",
      "4                      0.3413  \n",
      "5                      0.3397  \n",
      "6                      0.3333  \n",
      "7                      0.3557  \n",
      "8                      0.3300  \n",
      "9                      0.3408  \n",
      "10                     0.3478  \n",
      "11                     0.3117  \n",
      "12                     0.3476  \n",
      "13                     0.3311  \n",
      "14                     0.3065  \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Define model with regularization\n",
    "model_reg = models.Sequential([\n",
    "    layers.Flatten(input_shape=(32, 32, 3)),\n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile and train\n",
    "model_reg.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_reg = model_reg.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))\n",
    "\n",
    "# Compare accuracy before and after regularization\n",
    "accuracy_df[\"Training Accuracy (Reg)\"] = history_reg.history['accuracy']\n",
    "accuracy_df[\"Validation Accuracy (Reg)\"] = history_reg.history['val_accuracy']\n",
    "print(accuracy_df)\n",
    "\n",
    "# Explanation: Regularization reduces overfitting by preventing the network from relying too much on specific neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d90864b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 43ms/step - accuracy: 0.2339 - loss: 3.2817 - val_accuracy: 0.3606 - val_loss: 2.9496\n",
      "Epoch 2/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 39ms/step - accuracy: 0.3465 - loss: 2.9538 - val_accuracy: 0.3833 - val_loss: 2.8125\n",
      "Epoch 3/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 42ms/step - accuracy: 0.3749 - loss: 2.8162 - val_accuracy: 0.4132 - val_loss: 2.6673\n",
      "Epoch 4/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 40ms/step - accuracy: 0.3962 - loss: 2.6993 - val_accuracy: 0.4360 - val_loss: 2.5730\n",
      "Epoch 5/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 41ms/step - accuracy: 0.4131 - loss: 2.6037 - val_accuracy: 0.4409 - val_loss: 2.4930\n",
      "Epoch 6/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 41ms/step - accuracy: 0.4189 - loss: 2.5326 - val_accuracy: 0.4567 - val_loss: 2.4023\n",
      "Epoch 7/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 42ms/step - accuracy: 0.4382 - loss: 2.4367 - val_accuracy: 0.4693 - val_loss: 2.3339\n",
      "Epoch 8/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 37ms/step - accuracy: 0.4434 - loss: 2.3761 - val_accuracy: 0.4778 - val_loss: 2.2581\n",
      "Epoch 9/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 37ms/step - accuracy: 0.4492 - loss: 2.3126 - val_accuracy: 0.4623 - val_loss: 2.2188\n",
      "Epoch 10/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 40ms/step - accuracy: 0.4570 - loss: 2.2514 - val_accuracy: 0.4778 - val_loss: 2.1836\n",
      "Epoch 11/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 38ms/step - accuracy: 0.4627 - loss: 2.1999 - val_accuracy: 0.4819 - val_loss: 2.1186\n",
      "Epoch 12/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 43ms/step - accuracy: 0.4699 - loss: 2.1456 - val_accuracy: 0.4864 - val_loss: 2.0711\n",
      "Epoch 13/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 40ms/step - accuracy: 0.4741 - loss: 2.1012 - val_accuracy: 0.4948 - val_loss: 2.0180\n",
      "Epoch 14/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 40ms/step - accuracy: 0.4785 - loss: 2.0518 - val_accuracy: 0.4962 - val_loss: 1.9963\n",
      "Epoch 15/15\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 39ms/step - accuracy: 0.4851 - loss: 2.0086 - val_accuracy: 0.4870 - val_loss: 1.9723\n",
      "Epoch 1/15\n",
      "\u001b[1m 173/1563\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38\u001b[0m 71ms/step - accuracy: 0.1446 - loss: 3.5149"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_10156/3966414869.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      6\u001b[39m model_adam.compile(optimizer=\u001b[33m'adam'\u001b[39m, loss=\u001b[33m'sparse_categorical_crossentropy'\u001b[39m, metrics=[\u001b[33m'accuracy'\u001b[39m])\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Train models\u001b[39;00m\n\u001b[32m      9\u001b[39m history_sgd = model_sgd.fit(x_train, y_train, epochs=\u001b[32m15\u001b[39m, validation_data=(x_test, y_test))\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m history_adam = model_adam.fit(x_train, y_train, epochs=\u001b[32m15\u001b[39m, validation_data=(x_test, y_test))\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Plot accuracy comparison\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m matplotlib.pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    318\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;28;01min\u001b[39;00m epoch_iterator.enumerate_epoch():\n\u001b[32m    319\u001b[39m                     callbacks.on_train_batch_begin(step)\n\u001b[32m    320\u001b[39m                     logs = self.train_function(iterator)\n\u001b[32m    321\u001b[39m                     logs = self._pythonify_logs(logs)\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m                     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    323\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m self.stop_training:\n\u001b[32m    324\u001b[39m                         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    325\u001b[39m \n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/callbacks/callback_list.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m on_train_batch_end(self, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    104\u001b[39m         logs = logs \u001b[38;5;28;01mor\u001b[39;00m {}\n\u001b[32m    105\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;28;01min\u001b[39;00m self.callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m             callback.on_train_batch_end(batch, logs=logs)\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/callbacks/progbar_logger.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m on_train_batch_end(self, batch, logs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m         self._update_progbar(batch, logs)\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/callbacks/progbar_logger.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, batch, logs)\u001b[39m\n\u001b[32m     91\u001b[39m         self._maybe_init_progbar()\n\u001b[32m     92\u001b[39m         self.seen = batch + \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# One-indexed.\u001b[39;00m\n\u001b[32m     93\u001b[39m \n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.verbose == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m             self.progbar.update(self.seen, list(logs.items()), finalize=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/utils/progbar.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, current, values, finalize)\u001b[39m\n\u001b[32m    159\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;28;01min\u001b[39;00m self._values_order:\n\u001b[32m    160\u001b[39m                 info += \u001b[33mf\" - {k}:\"\u001b[39m\n\u001b[32m    161\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m isinstance(self._values[k], list):\n\u001b[32m    162\u001b[39m                     avg = backend.convert_to_numpy(\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m                         backend.numpy.mean(\n\u001b[32m    164\u001b[39m                             self._values[k][\u001b[32m0\u001b[39m] / max(\u001b[32m1\u001b[39m, self._values[k][\u001b[32m1\u001b[39m])\n\u001b[32m    165\u001b[39m                         )\n\u001b[32m    166\u001b[39m                     )\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, axis, keepdims)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"int\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m ori_dtype \u001b[38;5;28;01mor\u001b[39;00m ori_dtype == \u001b[33m\"bool\"\u001b[39m:\n\u001b[32m    570\u001b[39m         result_dtype = compute_dtype\n\u001b[32m    571\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    572\u001b[39m         result_dtype = ori_dtype\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     output = tf.reduce_mean(\n\u001b[32m    574\u001b[39m         tf.cast(x, compute_dtype), axis=axis, keepdims=keepdims\n\u001b[32m    575\u001b[39m     )\n\u001b[32m    576\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tf.cast(output, result_dtype)\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m op(*args, **kwargs)\n\u001b[32m     89\u001b[39m     bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m     90\u001b[39m     bound_arguments.apply_defaults()\n\u001b[32m     91\u001b[39m     bound_kwargs = bound_arguments.arguments\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(input_tensor, axis, keepdims, name)\u001b[39m\n\u001b[32m   2548\u001b[39m   keepdims = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m bool(keepdims)\n\u001b[32m   2549\u001b[39m   return _may_reduce_to_scalar(\n\u001b[32m   2550\u001b[39m       keepdims, axis,\n\u001b[32m   2551\u001b[39m       gen_math_ops.mean(\n\u001b[32m-> \u001b[39m\u001b[32m2552\u001b[39m           input_tensor, _ReductionDims(input_tensor, axis), keepdims,\n\u001b[32m   2553\u001b[39m           name=name))\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, axis)\u001b[39m\n\u001b[32m   2052\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x_rank:\n\u001b[32m   2053\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m constant_op.constant(np.arange(x_rank, dtype=np.int32))\n\u001b[32m   2054\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2055\u001b[39m       \u001b[38;5;66;03m# Otherwise, we rely on Range and Rank to do the right thing at run-time.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2056\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m range(\u001b[32m0\u001b[39m, array_ops.rank(x))\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1257\u001b[39m \n\u001b[32m   1258\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1259\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1260\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1261\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1262\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1263\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1264\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/tensorflow/python/ops/math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(start, limit, delta, dtype, name)\u001b[39m\n\u001b[32m   2023\u001b[39m     start = cast(start, inferred_dtype)\n\u001b[32m   2024\u001b[39m     limit = cast(limit, inferred_dtype)\n\u001b[32m   2025\u001b[39m     delta = cast(delta, inferred_dtype)\n\u001b[32m   2026\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m2027\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m gen_math_ops._range(start, limit, delta, name=name)\n",
      "\u001b[32m~/.local/lib/python3.11/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(start, limit, delta, name)\u001b[39m\n\u001b[32m   8020\u001b[39m         _ctx, \"Range\", name, start, limit, delta)\n\u001b[32m   8021\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   8022\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   8023\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m-> \u001b[39m\u001b[32m8024\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   8025\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   8026\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   8027\u001b[39m       return _range_eager_fallback(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Compile models with different optimizers\n",
    "model_sgd = models.clone_model(model_reg)\n",
    "model_adam = models.clone_model(model_reg)\n",
    "\n",
    "model_sgd.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_adam.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train models\n",
    "history_sgd = model_sgd.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))\n",
    "history_adam = model_adam.fit(x_train, y_train, epochs=15, validation_data=(x_test, y_test))\n",
    "\n",
    "# Plot accuracy comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_sgd.history['accuracy'], label='SGD - Train')\n",
    "plt.plot(history_sgd.history['val_accuracy'], label='SGD - Val')\n",
    "plt.plot(history_adam.history['accuracy'], label='Adam - Train')\n",
    "plt.plot(history_adam.history['val_accuracy'], label='Adam - Val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Analysis: Adam typically converges faster while SGD requires more epochs but sometimes generalizes better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfd1d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64]\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        model_tune = models.clone_model(model_reg)\n",
    "        model_tune.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \n",
    "                           loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        history_tune = model_tune.fit(x_train, y_train, epochs=15, batch_size=bs, validation_data=(x_test, y_test))\n",
    "        \n",
    "        results.append({\"Learning Rate\": lr, \"Batch Size\": bs, \"Final Accuracy\": history_tune.history['val_accuracy'][-1]})\n",
    "\n",
    "# Display results\n",
    "tuning_df = pd.DataFrame(results)\n",
    "print(tuning_df)\n",
    "\n",
    "# Explanation: Lower learning rates usually stabilize training, while batch size affects convergence speed.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
